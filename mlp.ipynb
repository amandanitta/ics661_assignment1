{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>...</th>\n",
       "      <th>0.608</th>\n",
       "      <th>0.609</th>\n",
       "      <th>0.610</th>\n",
       "      <th>0.611</th>\n",
       "      <th>0.612</th>\n",
       "      <th>0.613</th>\n",
       "      <th>0.614</th>\n",
       "      <th>0.615</th>\n",
       "      <th>0.616</th>\n",
       "      <th>0.617</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59994</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59999 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       5  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  ...  0.608  0.609  0.610  \\\n",
       "0      0  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "1      4  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "2      1  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "3      9  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "4      2  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "...   .. ..  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...    ...   \n",
       "59994  8  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "59995  3  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "59996  5  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "59997  6  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "59998  8  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "\n",
       "       0.611  0.612  0.613  0.614  0.615  0.616  0.617  \n",
       "0          0      0      0      0      0      0      0  \n",
       "1          0      0      0      0      0      0      0  \n",
       "2          0      0      0      0      0      0      0  \n",
       "3          0      0      0      0      0      0      0  \n",
       "4          0      0      0      0      0      0      0  \n",
       "...      ...    ...    ...    ...    ...    ...    ...  \n",
       "59994      0      0      0      0      0      0      0  \n",
       "59995      0      0      0      0      0      0      0  \n",
       "59996      0      0      0      0      0      0      0  \n",
       "59997      0      0      0      0      0      0      0  \n",
       "59998      0      0      0      0      0      0      0  \n",
       "\n",
       "[59999 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "display(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation = train_test_split(train,train_size=0.8,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.iloc[:,0]\n",
    "X_train = train.drop(train.columns[0],axis=1)\n",
    "\n",
    "y_validation = validation.iloc[:,0]\n",
    "X_validation = validation.drop(validation.columns[0],axis=1)\n",
    "\n",
    "y_test = test.iloc[:,0]\n",
    "X_test = test.drop(test.columns[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.ops as ops\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensors = torch.tensor(X_train.values,dtype=torch.float32)\n",
    "y_train_tensors = torch.tensor(y_train.values,dtype=torch.long)\n",
    "\n",
    "dataset_train = TensorDataset(X_train_tensors,y_train_tensors)\n",
    "train_loader = DataLoader(dataset_train,batch_size=64,shuffle=True)\n",
    "\n",
    "X_validation_tensors = torch.tensor(X_validation.values,dtype=torch.float32)\n",
    "y_validation_tensors = torch.tensor(y_validation.values,dtype=torch.long)\n",
    "\n",
    "dataset_validation = TensorDataset(X_validation_tensors,y_validation_tensors)\n",
    "validation_loader = DataLoader(dataset_validation)\n",
    "\n",
    "X_test_tensors = torch.tensor(X_test.values,dtype=torch.float32)\n",
    "y_test_tensors = torch.tensor(y_test.values,dtype=torch.long)\n",
    "\n",
    "dataset_test = TensorDataset(X_test_tensors,y_test_tensors)\n",
    "test_loader = DataLoader(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(18, 5))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.imshow(X_train.iloc[i].values.reshape(28,28), cmap='gray')\n",
    "    plt.subplots_adjust(wspace=0.2, hspace=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 10\n",
    "input_size = X_train.columns[0:].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(input_size,64), # input\n",
    "    nn.ReLU(), # activation\n",
    "    nn.Linear(64,32), # hidden layer\n",
    "    nn.ReLU(), # activation\n",
    "    nn.Linear(32,output_size), # ouput\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # loss function\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001) # optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in y_train: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique labels in y_train:\", torch.unique(y_train_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(model,loader):\n",
    "    num_epochs = 100\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        # Variables to accumulate predictions and true labels\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            # Forward pass: compute the output of the model\n",
    "            outputs = model(X_batch)\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            # Backward pass: compute gradients\n",
    "            optimizer.zero_grad()  # Clear previous gradients\n",
    "            loss.backward()        # Backpropagation\n",
    "\n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # Convert model outputs to predicted class indices\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            # Accumulate predictions and true labels\n",
    "            all_preds.extend(predicted.cpu().numpy())  # Convert to numpy and store\n",
    "            all_labels.extend(y_batch.cpu().numpy())   # Convert to numpy and store\n",
    "\n",
    "        # Compute metrics at the end of the epoch\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        f1 = f1_score(all_labels, all_preds, average='weighted')  # For multi-class problems\n",
    "        recall = recall_score(all_labels,all_preds, average='weighted')\n",
    "\n",
    "        # Print loss, accuracy, and F1 score every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}')\n",
    "        \n",
    "    print(f'Training Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}, F1: {f1:.4f}, Recall: {recall}')\n",
    "    return loss.item(), accuracy, f1, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.0514, Accuracy: 0.9961, F1 Score: 0.9961\n",
      "Epoch [20/100], Loss: 0.3005, Accuracy: 0.9952, F1 Score: 0.9952\n",
      "Epoch [30/100], Loss: 0.0000, Accuracy: 0.9961, F1 Score: 0.9961\n",
      "Epoch [40/100], Loss: 0.0061, Accuracy: 0.9959, F1 Score: 0.9959\n",
      "Epoch [50/100], Loss: 0.3685, Accuracy: 0.9964, F1 Score: 0.9964\n",
      "Epoch [60/100], Loss: 0.0000, Accuracy: 0.9961, F1 Score: 0.9961\n",
      "Epoch [70/100], Loss: 0.0188, Accuracy: 0.9969, F1 Score: 0.9969\n",
      "Epoch [80/100], Loss: 0.0828, Accuracy: 0.9954, F1 Score: 0.9954\n",
      "Epoch [90/100], Loss: 0.0004, Accuracy: 0.9971, F1 Score: 0.9971\n",
      "Epoch [100/100], Loss: 0.0000, Accuracy: 0.9968, F1 Score: 0.9968\n",
      "Training Loss: 0.0000, Accuracy: 0.9968, F1: 0.9968, Recall: 0.9968332673597367\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy, f1, recall = train_nn(model,train_loader)\n",
    "\n",
    "#print(f'{loss:.4f}, {accuracy}, {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_nn(model, X_set, y_set):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():  # No need to calculate gradients for validation/testing\n",
    "        outputs = model(X_set)\n",
    "        val_loss = criterion(outputs, y_set)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())  # Convert to numpy and store\n",
    "        all_labels.extend(y_set.cpu().numpy())   # Convert to numpy and store\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        f1 = f1_score(all_labels, all_preds, average='weighted')  # For multi-class problems\n",
    "        recall = recall_score(all_labels,all_preds, average='weighted')\n",
    "        \n",
    "        print(f'Loss: {val_loss.item():.4f}, Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, Recall: {recall:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.5639, Accuracy: 0.9667, F1 Score: 0.9668, Recall: 0.9667\n"
     ]
    }
   ],
   "source": [
    "evaluation_nn(model,X_validation_tensors, y_validation_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2860, Accuracy: 0.9679, F1 Score: 0.9679, Recall: 0.9679\n"
     ]
    }
   ],
   "source": [
    "evaluation_nn(model,X_test_tensors, y_test_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = nn.Sequential(\n",
    "    nn.Linear(input_size,64), # input\n",
    "    nn.ReLU(), # activation\n",
    "    nn.Linear(64,32), # hidden layer\n",
    "    nn.ReLU(), # activation\n",
    "    nn.Linear(32,20),\n",
    "    nn.ReLU(), # input\n",
    "    nn.Linear(20,output_size), # ouput\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # loss function\n",
    "optimizer = optim.Adam(model_2.parameters(),lr=0.001) # optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.2225, Accuracy: 0.9799, F1 Score: 0.9799\n",
      "Epoch [20/100], Loss: 0.0108, Accuracy: 0.9882, F1 Score: 0.9882\n",
      "Epoch [30/100], Loss: 0.0213, Accuracy: 0.9917, F1 Score: 0.9917\n",
      "Epoch [40/100], Loss: 0.0970, Accuracy: 0.9925, F1 Score: 0.9925\n",
      "Epoch [50/100], Loss: 0.0387, Accuracy: 0.9946, F1 Score: 0.9946\n",
      "Epoch [60/100], Loss: 0.0007, Accuracy: 0.9953, F1 Score: 0.9953\n",
      "Epoch [70/100], Loss: 0.1595, Accuracy: 0.9952, F1 Score: 0.9952\n",
      "Epoch [80/100], Loss: 0.0006, Accuracy: 0.9959, F1 Score: 0.9959\n",
      "Epoch [90/100], Loss: 0.0597, Accuracy: 0.9958, F1 Score: 0.9958\n",
      "Epoch [100/100], Loss: 0.0413, Accuracy: 0.9957, F1 Score: 0.9957\n",
      "Training Loss: 0.0413, Accuracy: 0.9957, F1: 0.9957, Recall: 0.9957082439217484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.04129088297486305,\n",
       " 0.9957082439217484,\n",
       " 0.9957080097760319,\n",
       " 0.9957082439217484)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nn(model_2,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3526, Accuracy: 0.9668, F1 Score: 0.9669, Recall: 0.9668\n"
     ]
    }
   ],
   "source": [
    "evaluation_nn(model_2,X_validation_tensors,y_validation_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3097, Accuracy: 0.9690, F1 Score: 0.9690, Recall: 0.9690\n"
     ]
    }
   ],
   "source": [
    "evaluation_nn(model_2,X_test_tensors,y_test_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
